{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moO0lk/LING227/blob/main/02_Introduction_to_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Relevant readings\n",
        "\n",
        "[NLTK Book, Chapter 1, Section 1.1, 1.2 and 1.3](https://www.nltk.org/book/ch01.html)"
      ],
      "metadata": {
        "id": "NlmcGT44dgJt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_vjnsOY-w-M"
      },
      "source": [
        "# Getting started with Natural Language Toolkit (NLTK)\n",
        "\n",
        "One of the primary libraries we will use is NLTK. The authors of NLTK have made a free textbook available, which this course uses some material from. This notebook covers how to get NLTK up and running in a Colab notebook.\n",
        "\n",
        "Sections 1.1 and 1.2 of Chapter 1 in the NLTK Book contain instructions for how to install Python and NLTK on your computer. If you are using Google Collaboratory, these points are not relevant. However, you are still encouraged to read these sections for a better understanding of how Python and NLTK would work outside of Google Colab.\n",
        "\n",
        "*A few other notes*\n",
        "- Google Colab does not have the `>>>` prompt mentioned in the NLTK book - this is replaced by the code cells in Colab.\n",
        "- the `generate()` function will not work.\n",
        "- there are likely many other little things that won't work based on various updates to Python/NLTK and/or the use of Google Colab, such as plotting and other functions which come later in the book. These also likely change over the years, so even things I think still work might not work later on. And other things which I need to provide workarounds for might no longer be problems - so bear with me!\n",
        "\n",
        "If there is a problem, don't worry about it for now, the NLTK book was written before notebooks were as widespread as they are now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hPAJpD5_NyT"
      },
      "source": [
        "## Accessing NLTK on Google Colab\n",
        "\n",
        "- NLTK is already pre-installed in Google Colab. But NLTK requires a lot of additional resources which we need to download. In section 1.2 of Chapter 1, the NLTK book explains that to access these resources one should use `nltk.download()`. We will use the same function but will not see the graphical downloader shown in the book.\n",
        "\n",
        "- For instance, one of the very first lessons in NLTK section 1.2 asks you to use `from nltk.book import *`, which means import everything from `nltk.book` (the `*` means everything). However you will get an error if you try this in Colab because the `book` data has not yet been downloaded.\n",
        "\n",
        "- When you do not have the right resource to run a particular NLTK function, you will see an error which looks like this:\n",
        ">> ![error](https://drive.google.com/uc?id=1nt76M0KbiLueTYHb72HSFnREC9_1DsM4)\n",
        "\n",
        "- If you see this error, don't panic! It just means you are missing a specific resource. In this example, the part that I selected in yellow is what is missing - in this case it is the resource `stopwords`. All you need to do is ask Colab to download the resource using the `nltk.download()` function. Because the Colab notebook is running on a temporary server, you will need to repeat this each time you connect to a new session. Fortunately, it does not take very long to download the data.\n",
        "\n",
        "You can specify which resources you need by passing each resource as a `string` inside a single `list`, a data container which is delimted by square brackets `[]`). We will talk about lists in more detail later, so you can simply run the code cell below to use this notebook.\n",
        "\n",
        "In the example below, I include a wide range of specific resources which you will need for the first chapter of NLTK.\n",
        "\n",
        "```\n",
        "# define a list of resources and save to variable\n",
        "nltk_resources = ['gutenberg', 'genesis', 'inaugural', 'nps_chat', 'webtext',\n",
        " 'treebank', 'stopwords', 'punkt', 'brown', 'reuters', 'udhr', 'words', 'names', 'cmudict', 'swadesh', 'wordnet', 'state_union']\n",
        "\n",
        "# Pass the list to nltk.download(), which will then download each resource\n",
        "nltk.download(nltk_resources)\n",
        "```\n",
        "\n",
        "Once you have sorted out your ability to access NLTK resources, you are ready to go through the rest of the notebook lessons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpUZxNNO-tL3"
      },
      "outputs": [],
      "source": [
        "# import the main nltk module\n",
        "import nltk\n",
        "\n",
        "# create a list of resources we will need for this notebook\n",
        "nltk_resources = ['gutenberg', 'genesis', 'inaugural', 'nps_chat', 'webtext', 'treebank', 'stopwords', 'punkt', 'brown', 'reuters', 'udhr', 'words', 'names', 'cmudict', 'swadesh', 'wordnet', 'state_union']\n",
        "\n",
        "# download them (here I pass the variable name to the function, which contains all the strings of the resources I want.)\n",
        "nltk.download(nltk_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muY7BdQQDlq4"
      },
      "source": [
        "# Searching Text\n",
        "\n",
        "Chapter 1 asks you to load in a series of books and corpora which are stored in NLTK as examples. Take a moment to look at the names of the files - some are single books and movie scripts, while others are different corpora. What is the difference between the two? A book is simply a stand-alone book, whereas a corpus is a large collection of text from similar texts/documents, which can be longer or shorter than a single book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPoI-04vK23i"
      },
      "outputs": [],
      "source": [
        "# import everything from ntlk.book()\n",
        "# the * stands as a wildcard which means \"anything\"\n",
        "from nltk.book import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWt6zMhZO_d4"
      },
      "source": [
        "## Concordance Lines\n",
        "\n",
        "NLTK starts off with concordances, which is a method that draws from corpus linguistics to analyse the meanings and/or functions of different words in texts. This method is fundamental for performing corpus analysis because a concordance will let you see a single word or patterns of words **in context** of the surrounding words.\n",
        "\n",
        "The example in the NLTK book is to search for the word `monstrous` in *Moby Dick*.\n",
        "\n",
        "Here are some other collocations I searched for based on my own guesses about what you might find in the differnt corpora. Feel free to play around and look for your own words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgIRw-NLNanl"
      },
      "outputs": [],
      "source": [
        "# search for \"color\" in Holy Grail\n",
        "text6.concordance('color')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwejNvI2Pco2"
      },
      "outputs": [],
      "source": [
        "# search for \"like\" in webchat\n",
        "text5.concordance('like')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvuLwCbGP2G1"
      },
      "outputs": [],
      "source": [
        "# search for 'looking' in the personals corpus\n",
        "text8.concordance('looking')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw_4SPh9QcKc"
      },
      "source": [
        "# Comparing words\n",
        "\n",
        "What you probably noticed is that words are used in specific ways in different corpora. This relatively simple anlaysis has thus already told us something about the way language works: context determines the way words are used and understood. Corpus linguistic anlaysis is thus a crucial way to gain a better understanding of word meanings and language use.\n",
        "\n",
        "\n",
        "The `.similar()` and `.common_contexts()` functions from the NLTK texts allow you to find words that are used in the same contexts. This means words which occur before/after the same other words. For example, in the following two sentences the words \"truck\" and \"apple\" are similar because they both occur after the word \"red\":\n",
        "\n",
        "- A big red truck\n",
        "- A big red apple\n",
        "\n",
        "\n",
        "Try testing the word \"hello\" using the `.similar()` method in different corpora. The output that you see represents words that are used in similar contexts are your input word.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Yzjt9XgRyDv"
      },
      "outputs": [],
      "source": [
        "# which words occur in the same contexts as 'green' in Monty Python?\n",
        "text6.similar('green')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify this by looking at the concordance lines for those words...we can see that both \"green\" and \"black\" occur before the word \"knight\". While interesting, the `.similar()` function is admittedly difficult to use in a meaningful way - we will get to collocations and word probabilities later on to see better ways of capturing these relationships."
      ],
      "metadata": {
        "id": "IqOUE0OHzTs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text6.concordance('green')"
      ],
      "metadata": {
        "id": "xMNmiRSuzXO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text6.concordance('black')"
      ],
      "metadata": {
        "id": "Z7BReWejzc-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITaNH55-STr_"
      },
      "source": [
        "The `.common_contexts()` method allows you to compare two words in the same text. The book uses the example of testing `monstrous` and `very` in Moby Dick. The book asks you to pick two words of your own and compare them. If you're like me, you will see that many times you have no results because the words you searched for do not occur in the corpus or do not have any common contexts - this further demonstrates how we can predict the types of words based on our knowldge of the corpus.\n",
        "\n",
        "Please note that the two words you are searching for are placed inside square brackets `[]`, and separated by a comma. This is a `list`, which we will learn about in an upcoming notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test commmon contexts with 'green' and 'black'\n",
        "text6.common_contexts(['green', 'black'])"
      ],
      "metadata": {
        "id": "SH5DQtQ30GSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3kRvLGDSoDY"
      },
      "outputs": [],
      "source": [
        "# do hello and goodbye have simlar contexts in the webchat corpus?\n",
        "text5.common_contexts(['hello', 'goodbye'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptdcp6ZcS0_o"
      },
      "outputs": [],
      "source": [
        "# what about 'hi' and 'bye' in the webchat corpus?\n",
        "text5.common_contexts(['hi', 'bye'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3povNiVTgw1"
      },
      "outputs": [],
      "source": [
        "# how about \"hi\" and \"bye\" in the personals?\n",
        "text8.common_contexts(['hi', 'bye'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI5tcSgM97fw"
      },
      "outputs": [],
      "source": [
        "# these words in moby dick?\n",
        "text1.common_contexts(['white', 'whale'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twABRQEGTeip"
      },
      "source": [
        "If we wanted to make sure the words are actually in the corpus before running the function, we could use the `in` conditional statement and check the `.vocab()` method of the corpus (which is a list of the words in the corpus!). We will learn more about conditional statements later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja4ltQ5gPpNN"
      },
      "outputs": [],
      "source": [
        "# check if a word is are in the corpus text\n",
        "'like' in text5.vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4bLVmAjT8cX"
      },
      "outputs": [],
      "source": [
        "'knight' in text6.vocab()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Your Turn**\n",
        "\n",
        "1. Spend a few moments using the `.concordance()` function to search for different words in the texts. See if you can find any interesting examples and share with the class.  \n",
        "\n",
        "2. After looking through some concordances, play with the `.similar()` and `.common_contexts()` functions to see if you can find words used in similar contexts.\n",
        "\n",
        "3. What can this analysis tell us, if anything, about the nature of the different texts?\n",
        "\n"
      ],
      "metadata": {
        "id": "ndhkAGve8xv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "text4.concordance(\"while\")\n",
        "len(text4)"
      ],
      "metadata": {
        "id": "uOH_Yz8A6FIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 similar\n",
        "text6.similar(\"tho\")"
      ],
      "metadata": {
        "id": "Vzw_dcth7dS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 common contexts\n",
        "text4.common_contexts([\"the\", \"how\"])"
      ],
      "metadata": {
        "id": "K4oOt9-F7qrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\n"
      ],
      "metadata": {
        "id": "UFKS1aM78FDq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}